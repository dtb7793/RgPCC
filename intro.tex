\documentclass[main.tex]{subfiles}

\begin{document}
\section{Introduction}
Principal component regression (PCR) was introduced (by Jeffers, 1967) to deal with multicollinearity. This method can achieve dimension reduction and improve prediction performance compared to ordinary least squares. However, its downfall in regression is that the principal components depend soley on the design $\X$ and in this sense the variable selection is "blind", as it does not take the response into account. In early 2020 Lang and Zou \cite{langzou} introduced Response-guided Principal Component Regression (RgPCR) to remedy the "blind" selection of PCR. This is done by replacing the hard-thresholding of PCR with soft-thresholding via a penalty function. The result is that both the variance of the predictors and the association with the response of principal components is taken into account during thresholding.

In this paper, we will combine RgPCR with logistic regression for binary classification. To do this we optimized a penalized log likelihood function by quadratically approximating and taking advantage of the principal components of ``psuedo data" in the resulting expression. The result is a principal component classification algorithm that takes the response into account during variable selection.

In section 2 we will give our motivation and cover the background knowledge necessary. In section 3 we will derive the RgPCC algorithm. In sections 4 and 5 we will compare the performance of RgPCC against other methods on simulated data and then on realworld data. Lastly, in section 6 and 7 we will propose further topics of study and summarize our results.

\end{document}
