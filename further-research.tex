\documentclass[main.tex]{subfiles}

\begin{document}
\section{Conclusions and Further Research}

In this section we give some conclusions and mention topics for further research.

\subsection{Conclusions}

In the above we have proposed response-guided principal component classification (RgPCC) as alternative to principal component classification and logistic regression. We have illustrated its practice on simulated and real data as a classification method and a probability density esitmator with reasonable evidence of its better performance.

We have limited the above to the lasso penalty for our thresholding rule as an initial ``proof of concept" for this method. In further research we plan to vary the thresholding function or even use data to inform the choice of thresholding function.

\subsection{Further Research}
\subsubsection{Speed}
This method of RgPCC improves upon testing error in binary classification compared to logistic regression. We also believe that this use of principal component analysis should improve the speed of the computation, especially when there is sparsity in the solution with respect to the principal components. We wish to further explore this, especially in higher dimensions and when $p > N$.

\subsubsection{$C_p$-type Statistic for Parameter Tuning}
Using cross-validation for parameter selection is data and time intensive. In Zou and Lang's paper \cite{langzou}, the regularization parameter in RgPCR can be selected using Stein's unbiased risk estimation. In later works, we will also investigate if this method can be generalized to RgPCC.

\subsubsection{Further Generalization}
In many cases, data is not presented in a manner such that classes are linearly separable. Kernel methods embed data in higher dimensional spaces in a way that makes classes linearly separable, without have to work in the higher dimensional space directly. We would like to be able to apply RgPCC in these nonlinear cases as well.

We would also like to extend this to multiclass classification through ideas from logistic regression for multiclass classification. We can also take the ideas from \cite{wangleng} to generalize this method to other classifiers such as SVM.

\end{document}